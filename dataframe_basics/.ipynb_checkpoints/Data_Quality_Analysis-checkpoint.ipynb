{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf5c796",
   "metadata": {},
   "source": [
    "# data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe3c44",
   "metadata": {},
   "source": [
    "**Note**: The following questions aim to help you deal with the topic of data quality and to deal with issues relating to data fitness, etc.\n",
    "the main question is:\n",
    "> What do you think of the dataset? Is it appropriate to answer the question about employee satisfaction? Is the information provided sufficient to answer the question? If not, what other information would you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce54cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'],\n",
    "        'Age':[20, 21, 19, 18]}\n",
    "\n",
    "df_es = pd.read_csv(\"./data/employees_satisfaction.csv\", index_col=0)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#df_dss = pd.read_csv(\"./data/Latest_Data_Science_Salaries.csv\", index_col=0)\n",
    "#ppp_data_recent = pd.read_csv('./data/public_150k_plus_230630.csv')\n",
    "#ppp_data = pd.read_csv('./data/public_up_to_150k_1_230630.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26375d9",
   "metadata": {},
   "source": [
    "Data quality is the assessment of usefulness and reliability of data to serve its purpose.\n",
    "\n",
    "There are two axis of Data Quality:\n",
    "1. the integrity of the data itself\n",
    "2. and the fit or appropriateness of the dataset with respect to a particular question or data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3e12d",
   "metadata": {},
   "source": [
    "### 1. Data Integrety:\n",
    "\n",
    "The integrity of a dataset is evaluated using the data values and the desctiptives that make it up.\n",
    "\n",
    "Data integrity focuses on the quality of the data, or its accuracy. It strives to eliminate errors and redundant information, and to fill in missing information.\n",
    "\n",
    "Data integrity requires that data meets the following 10 characteristics: \n",
    "1. _**high volume**_: \n",
    "2. _**of known provenance**_:\n",
    "3. _**well-annotated**_:\n",
    "4. _**timely**_:\n",
    "5. _**complete**_: Completeness of data means that the main features/attributes required for the analysis do not have missing values. Missing values can skew the analysis and lead to misleading trends.\n",
    "6. _**multivariant**_:\n",
    "7. _**atomic**_:\n",
    "8. _**consistent**_:\n",
    "9. _**dimensionally structured**_:\n",
    "10. _**clear**_:\n",
    "\n",
    "Let's see what strategies we can use to assess each of these characteristics. \n",
    "\n",
    "\n",
    "**1.1. High Volume**:\n",
    "Assesses whether the volume of the dataset is enough to answer your question. At minimum, a dataset will need to have sufficient records to support the type of analysis needed to answer your particular question. If what you need is a count—for example, the number of 311 calls that involved noise complaints in a particular year—then having “enough” data means having records of all of the 311 calls for that particular year.\n",
    "\n",
    "> _important questions would be:_\n",
    ">* _Is the number of data in your dataset is enough?_\n",
    "\n",
    "**_Lösung:_**\n",
    "From the meta data and supporting documents, we know, that all employee records of the company are listed in this dataset, which means that the volume of the dataset is sufficient for the purpose of this survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1176cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does this dataset include all 500 employees of this company? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Does this dataset include all 500 employees of this company? \"+str(len(df_es.index)==500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2888b",
   "metadata": {},
   "source": [
    "**1.2. Complete**: \n",
    "\n",
    "The metrics to measure the ratio of missing records for the features that are necessary (not optional) for the analysis. For example, if 30 out of 100 records in your analysis is missing the industry feature that you need for your marketing campaign, the completeness of your data is 70%.\n",
    "\n",
    "> _important questions would be:_\n",
    ">* _Are there any missing values in the data?_\n",
    ">* _Find the earliest date(s) in our “recent” data file and confirm that they are before a specific date._\n",
    "\n",
    "> _in case of two data sets:_\n",
    ">* _Compare the file sizes and/or row counts of the two datasets to confirm that the more recent file is larger than the older file._\n",
    ">* _Compare the data they contain to confirm that all the records in the earlier file already exist in the later file._\n",
    "\n",
    "One important thing here is that not every kind of missing data can be detected by the default method of the pandas library e.g. if the missing value has been encoded as an empty string or arbitrary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdcf99b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sum of all Nans? 506\n",
      "Sum of all Nans? emp_id                0\n",
      "age                   0\n",
      "Dept                  0\n",
      "education             0\n",
      "recruitment_type      0\n",
      "job_level             0\n",
      "rating               29\n",
      "awards                0\n",
      "certifications        0\n",
      "salary                0\n",
      "gender                3\n",
      "entry_date            0\n",
      "last_raise          474\n",
      "satisfied             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#for exapmple by checking for NANs\n",
    "\n",
    "check = df_es.isnull()\n",
    "\n",
    "if(check.values.any()):\n",
    "    print(\"Sum of all Nans? \"+str(check.values.sum())); \n",
    "    \n",
    "#sum of nans per column\n",
    "print(\"Sum of Nans per column? \"+str(check.sum()))\n",
    "\n",
    "#You can replace NAN values with a string of your choice if you want\n",
    "#missing_value.replace(np.nan, 'N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fd065",
   "metadata": {},
   "source": [
    "You can check for the count of all the values in a column.\n",
    "By default, there is a ```dropna``` argument that controls the behavior of this function.\n",
    "You have to explicitly pass it to the function to make it return the missing value as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b5afc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "m         207\n",
      "f         187\n",
      "Male       57\n",
      "Female     46\n",
      "Name: count, dtype: int64\n",
      "gender\n",
      "m         207\n",
      "f         187\n",
      "Male       57\n",
      "Female     46\n",
      "NaN         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_es['gender'].value_counts())\n",
    "#or\n",
    "print(df_es['gender'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451cb30d",
   "metadata": {},
   "source": [
    "You can also find the earliest date(s) in our “recent” data file and confirm that they are before June 30, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "490b37a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-01-05 00:00:00\n",
      "2020-12-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# convert the values in the `entry_date` column to *actual* dates\n",
    "df_es['entry_date'] = pd.to_datetime(df_es['entry_date'], format='%Y-%m-%d')\n",
    "\n",
    "# print out the `min()` and `max()` values in the `entry_date` column\n",
    "print(df_es['entry_date'].min())\n",
    "print(df_es['entry_date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ad94c",
   "metadata": {},
   "source": [
    "In section X we talk about ways to replace missing values.\n",
    "\n",
    "**1.3. Consistent**: \n",
    "\n",
    "Consistency refers to the lack of contradictions within a dataset or between different datasets. A 5-feet tall newborn or mismatching revenue between sales and usage tables are both examples of inconsistency in the data.\n",
    "\n",
    "> _important questions would be:_\n",
    ">* _are there duplicates?_\n",
    ">* _Do the data match when thy are read from two different sources?_\n",
    ">* are the decriptives used for the same value in the dataset consistent? (e.g. spelling of \"male\" vs \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#are there duplicates?\n",
    "print(df_es.duplicated())\n",
    "print(df_dss[df_dss.duplicated()])\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#you can drop duplicates as follows:\n",
    "#df_dss.drop_duplicates() \n",
    "\n",
    "#Also, you can detect partial duplication by specifying your target columns.\n",
    "df_dss[df_dss.duplicated(['Salary','Company Location'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f06bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Female     46\n",
      "Male       57\n",
      "f         187\n",
      "m         207\n",
      "Name: emp_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#are the decriptives used for the same value in the dataset consistent? e.g. spelling of \"male\" vs \"Male\"\n",
    "#find inconsistencies:\n",
    "print(df.groupby(['gender'])['emp_id'].count())\n",
    "print(\"--------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba7936",
   "metadata": {},
   "source": [
    "**1.4. timely**: \n",
    "\n",
    "Timeliness ensures that data is up to date and the most recent records reflect the most recent changes.\n",
    "\n",
    "> _important questions would be:_\n",
    ">* _is the dataset up to date?_\n",
    ">* _does the dataset include the most recent records?_\n",
    ">* _when was the last time the data was updated?_\n",
    ">* _What are the minimum and maximum dates in the table?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3717721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "011f115b",
   "metadata": {},
   "source": [
    "**1.5. Of known Provenance**: \n",
    "\n",
    "The dataset is from a reliable source.\n",
    "\n",
    "> _important questions would be:_\n",
    ">* _is the dataset from a reliable source?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b9f028",
   "metadata": {},
   "source": [
    "### 2. Data Fitness:\n",
    "\n",
    "There are 3 Metrics of data fitness:\n",
    "1. Validity.\n",
    "2. Reliability\n",
    "3. Representativeness.\n",
    "\n",
    "**2.1. Validity**:\n",
    "\n",
    "Validity means that data has the right type, format and range. Data has the right type and format if it conforms to a set of pre-defined standards and definitions: 08–12–2019 is invalid when the standard format is defined as YYYY/mm/dd.\n",
    "\n",
    "In the meantime, validity assures that data is in an acceptable range. Outliers, an important concept in Statistics and Data Science, are datapoints that do not meet this requirement.\n",
    "\n",
    "> _important questions would be:_\n",
    ">* _Are there any outliers? Boxplot is a simple approach to identify outliers_\n",
    ">* _Are type and format of ata correct and consistent? e.g. date formats_\n",
    "\n",
    ">**PS**: Boxplots visualize a distribution by plotting the five important numbers: minimum, maximum, 25th percentile, median and 75th percentile of the distribution. To find outliers in the data, look at the regions that are 1.5 IQR (Interquartile Range) smaller than 25th or greater than 75th percentiles where IQR is the distance between 75th and 25th percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85885e",
   "metadata": {},
   "source": [
    "[^1]: MYr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01293b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
