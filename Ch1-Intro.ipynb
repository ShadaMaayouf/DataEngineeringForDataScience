{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# 1. Introduction to Data Wrangling and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Quality\n",
    "2. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling\n",
    "\n",
    "- is the process of taking “raw” or “found” data, and transforming it into something that can be used to generate insight and meaning. \n",
    "\n",
    "-  it is about much more than simply learning how to access and manipulate data; it’s about making judgments, inferences, and selections.\n",
    "\n",
    "- Every significant data manipulation task is propelled by a **question**.\n",
    "\n",
    "-  the data wrangling process is really more of a **cycle** than it is a linear set of steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps of data wrangling:\n",
    "1. Researching.\n",
    "2. Locating or collecting data\n",
    "3. Reviewing the data\n",
    "4. “Cleaning,” standardizing, transforming, and/or augmenting the data\n",
    "5. Analyzing the data\n",
    "6. Visualizing the data\n",
    "7. Communicating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality\n",
    "\n",
    "- It it is up to the humans involved in data collection, acquisition, and analysis to ensure its quality so that the outputs of our data work actually mean something.\n",
    "\n",
    "- axes for evaluating data quality:\n",
    "1. the **integrity** of the data itself, \n",
    "2. and the “**fit**” or appropriateness of the data with respect to a particular question or problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data Fit\n",
    "\n",
    "-  often we have to do a significant amount of integrity work before we can know with confidence that our dataset is actually fit for our selected question or project.\n",
    "\n",
    "> **Definition** *Data Fit*\n",
    ">\n",
    "> The extent to which a given dataset accurately represents the phenomenon you're investigatig.\n",
    "\n",
    "Data fit is based on **3 metrics**: *validity*, *reliability*, and *representativeness*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Validity** \n",
    "\n",
    "Describes the extent to which something measuresa what it is supposed to.\n",
    "\n",
    "\n",
    "- **Construct Validity**: This refers to how well a test or tool measures the theoretical construct that it was designed to measure¹². For example, if a test is designed to measure introversion, construct validity would be the degree to which the test actually measures introversion¹. It's especially important when researching concepts that can't be quantified and/or are intangible¹.\n",
    "\n",
    "- **Content Validity**: This assesses how well a test represents all aspects of the construct¹². If a test is designed to measure introversion, content validity would be the degree to which the test covers all aspects of introversion¹. If some aspects are missing or irrelevant parts are included, the test has low content validity¹.\n",
    "\n",
    "In summary, construct validity is about the test measuring what it's supposed to measure, while content validity is about the test covering the full breadth of the concept¹²."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Reliability\n",
    "\n",
    "Reliability of a given measure describes its accuracy and stability. Together they help us assess whether the same measure taken twice in the same circumstances will give us the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Representativeness\n",
    "\n",
    "Reliability of a given measure describes whether those insights are an accurate portrait of a particular situation or population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data integrity\n",
    "\n",
    "the integrity of a dataset is evaluated using the data values and descriptors that make it up.\n",
    "\n",
    "Data integrity is about whether the data you have can support the analysis you''ll need to perform in order to answer that quastion.\n",
    "\n",
    "> **Definition** *Data Integrity*\n",
    ">\n",
    ">Data Integrity is the completeness, accuracy, and consistency of data as it is maintained over time and across all formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data integrity is based on the following **metrics**: \n",
    "\n",
    "- ***Necessary, but not sufficient***\n",
    "    - Of known provence.\n",
    "    - Well-Annotated.\n",
    "- ***Important***\n",
    "    - Timely.\n",
    "    - Complete.\n",
    "    - High Volume.\n",
    "    - Multivariant.\n",
    "    - Atomic\n",
    "- ***Achievable***\n",
    "    - Consistent.\n",
    "    - Clear.\n",
    "    - Dimensionally structed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are short explanations for each of the points:\n",
    "\n",
    "***Necessary, but not sufficient***\n",
    "- **Of known provenance**: This means the data's origin or source is known and can be traced. It's necessary for data integrity and authenticity, but not sufficient alone for overall data quality.\n",
    ">* _is the dataset from a reliable source?_\n",
    "- **Well-Annotated**: This refers to data being accompanied by explanatory information (annotations). While necessary for understanding the data, it alone doesn't guarantee the data's accuracy or relevance.\n",
    "\n",
    "***Important***\n",
    "- **Timely**: This means the data is available when needed. Timeliness is important for data to be actionable, but it doesn't ensure other aspects like accuracy or completeness.\n",
    ">* _is the dataset up to date?_\n",
    ">* _does the dataset include the most recent records?_\n",
    ">* _when was the last time the data was updated?_\n",
    ">* _What are the minimum and maximum dates in the table?_\n",
    "- **Complete**: Complete data has all the necessary parts. It's important for a comprehensive analysis, but doesn't ensure the data is timely or accurate.\n",
    "> _important questions would be:_\n",
    ">* _Are there any missing values in the data?_\n",
    ">* _Find the earliest date(s) in our “recent” data file and confirm that they are before a specific date._\n",
    "- **High Volume**: This refers to having a large amount of data, which is important for statistical significance. However, high volume doesn't ensure the data is relevant or accurate.\n",
    ">Is the number of data in your dataset is enough?\n",
    "- **Multivariant**: This means the data covers multiple variables or factors. It's important for a holistic view, but doesn't ensure the data is complete or timely.\n",
    "- **Atomic**: This refers to data that is in its smallest indivisible unit, providing a high level of detail. It's important for granular analysis, but doesn't ensure the data is complete or timely.\n",
    "\n",
    "***Achievable***\n",
    "- **Consistent**: This means the data is uniform and reliable across all instances. It's achievable with good data governance, but doesn't ensure the data is timely or complete.\n",
    "> _important questions would be:_\n",
    ">* _are there duplicates?_\n",
    ">* _Do the data match when thy are read from two different sources?_\n",
    ">* are the decriptives used for the same value in the dataset consistent? (e.g. spelling of \"male\" vs \"Male\")\n",
    "- **Clear**: This refers to data that is easy to understand and interpret. It's achievable with good data presentation, but doesn't ensure the data is accurate or complete.\n",
    "- **Dimensionally Structured**: This means the data is organized in a way that allows analysis across different dimensions (e.g., time, location). It's achievable with good data modeling, but doesn't ensure the data is timely or accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
